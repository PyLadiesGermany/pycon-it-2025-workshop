{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b28efe7",
   "metadata": {},
   "source": [
    "# Train Model for Carbon Intensity Prediction 扁\n",
    "\n",
    "This script trains a model to predict carbon intensity using the provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2247d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer, \n",
    "    pipeline\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7078c",
   "metadata": {},
   "source": [
    "### 1. Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d721029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_carbon_intesity_for_activites.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "# Map labels to ints\n",
    "label_names = [\"low\", \"medium\", \"high\"]\n",
    "label2id = {name: i for i, name in enumerate(label_names)}\n",
    "id2label = {i: name for i, name in enumerate(label_names)}\n",
    "df[\"label\"] = df[\"label\"].map(label2id)\n",
    "\n",
    "# Split train/test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "\n",
    "# Convert to Hugging Face datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656b6127",
   "metadata": {},
   "source": [
    "### 2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5efbc5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2dbc81790c420d99b9199844e82016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c312810a5940b2beca6d6ce8ba4b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def preprocess(example):\n",
    "    return tokenizer(example[\"activity\"], truncation=True, padding=\"max_length\", max_length=32)\n",
    "\n",
    "dataset = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef961a84",
   "metadata": {},
   "source": [
    "### 3. Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e8b95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    num_labels=len(label_names),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18338b9b",
   "metadata": {},
   "source": [
    "### 4. Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0a3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"carbon-intensity-classifier\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=2e-5,\n",
    "    logging_steps=5,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=\"jessica-ecosia/carbon-intensity-classifier\",  # change if you want to push to your own account\n",
    "    hub_strategy=\"end\",\n",
    "    report_to=\"codecarbon\",  # to report metrics to CodeCarbon\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067a52d",
   "metadata": {},
   "source": [
    "### 5. Trainer and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2abfba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fg/sdhdjs9d49z5tc2s3p0lkxb80000gn/T/ipykernel_43132/1790462302.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[codecarbon WARNING @ 14:02:25] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[codecarbon WARNING @ 14:02:25] Error while trying to count physical CPUs: [Errno 2] No such file or directory: 'lscpu'. Defaulting to 1.\n",
      "[codecarbon INFO @ 14:02:25] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 14:02:25] [setup] CPU Tracking...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[codecarbon WARNING @ 14:02:25] We saw that you have a Apple M2 Pro but we don't know it. Please contact us.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[codecarbon WARNING @ 14:02:25] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Mac OS and ARM processor detected: Please enable PowerMetrics sudo to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 14:02:25] CPU Model on constant consumption mode: Apple M2 Pro\n",
      "[codecarbon WARNING @ 14:02:25] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 14:02:25] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 14:02:25] No GPU found.\n",
      "[codecarbon INFO @ 14:02:25] The below tracking methods have been set up:\n",
      "                RAM Tracking Method: RAM power estimation model\n",
      "                CPU Tracking Method: global constant\n",
      "                GPU Tracking Method: Unspecified\n",
      "            \n",
      "[codecarbon INFO @ 14:02:25] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 14:02:25]   Platform system: macOS-15.0.1-arm64-arm-64bit\n",
      "[codecarbon INFO @ 14:02:25]   Python version: 3.11.2\n",
      "[codecarbon INFO @ 14:02:25]   CodeCarbon version: 3.0.2\n",
      "[codecarbon INFO @ 14:02:25]   Available RAM : 32.000 GB\n",
      "[codecarbon INFO @ 14:02:25]   CPU count: 10 thread(s) in 1 physical CPU(s)\n",
      "[codecarbon INFO @ 14:02:25]   CPU model: Apple M2 Pro\n",
      "[codecarbon INFO @ 14:02:25]   GPU count: None\n",
      "[codecarbon INFO @ 14:02:25]   GPU model: None\n",
      "[codecarbon INFO @ 14:02:26] Emissions data (if any) will be saved to file /Users/jessica-g/Documents/pycon-us-2024-workshop-start-branch/model_training/carbon-intensity-classifier/emissions.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.979600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.953500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.735500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.730900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.700900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 14:02:33] Energy consumed for RAM : 0.000011 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 14:02:33] Delta energy consumed for CPU with constant : 0.000081 kWh, power : 42.5 W\n",
      "[codecarbon INFO @ 14:02:33] Energy consumed for All CPU : 0.000081 kWh\n",
      "[codecarbon INFO @ 14:02:33] 0.000093 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=0.8773746252059936, metrics={'train_runtime': 6.88, 'train_samples_per_second': 47.965, 'train_steps_per_second': 7.267, 'total_flos': 2732188821120.0, 'train_loss': 0.8773746252059936, 'epoch': 10.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\")\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c7c267-28c2-4d39-80b2-2879a34aa7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "YOUR_HUGGINGFACE_TOKEN 路路路路路路路路\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "hugging_face_token = getpass(\"YOUR_HUGGINGFACE_TOKEN\")\n",
    "\n",
    "login(token=hugging_face_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58470d",
   "metadata": {},
   "source": [
    "### 7. Save final model to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74487163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785f107ceb2640d7a8821e41dd5bb516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a9ac89709849b890f5eca40a270bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02230742728d462b96b1eda3c40001e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=8aee037de89e4c617eb129a7c5d417afc54e3e28399944d8c2f7849d75fccd82&X-Amz-SignedHeaders=host&partNumber=1&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2393)')))\"), '(Request ID: a285da0a-5809-4b2e-875b-819ffe01507f)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=8aee037de89e4c617eb129a7c5d417afc54e3e28399944d8c2f7849d75fccd82&X-Amz-SignedHeaders=host&partNumber=1&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=fd934521eed7655cd9509e70ee11b095bdd91e67a86009cec0727c348358d8f8&X-Amz-SignedHeaders=host&partNumber=4&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2393)')))\"), '(Request ID: b544b27b-9acd-4986-8358-659254c03d13)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=fd934521eed7655cd9509e70ee11b095bdd91e67a86009cec0727c348358d8f8&X-Amz-SignedHeaders=host&partNumber=4&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=fd934521eed7655cd9509e70ee11b095bdd91e67a86009cec0727c348358d8f8&X-Amz-SignedHeaders=host&partNumber=4&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2393)')))\"), '(Request ID: ec2b5b7f-9d93-4277-9c6f-e526799c2578)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=fd934521eed7655cd9509e70ee11b095bdd91e67a86009cec0727c348358d8f8&X-Amz-SignedHeaders=host&partNumber=4&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=fd934521eed7655cd9509e70ee11b095bdd91e67a86009cec0727c348358d8f8&X-Amz-SignedHeaders=host&partNumber=4&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2393)')))\"), '(Request ID: f1b941f1-5ba4-4895-870f-fe420a28c7eb)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=fd934521eed7655cd9509e70ee11b095bdd91e67a86009cec0727c348358d8f8&X-Amz-SignedHeaders=host&partNumber=4&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=fd934521eed7655cd9509e70ee11b095bdd91e67a86009cec0727c348358d8f8&X-Amz-SignedHeaders=host&partNumber=4&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x169e00310>, 'Connection to hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com timed out. (connect timeout=None)'))\"), '(Request ID: 5bd05e34-d049-4929-894f-15a60a1e54d3)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=fd934521eed7655cd9509e70ee11b095bdd91e67a86009cec0727c348358d8f8&X-Amz-SignedHeaders=host&partNumber=4&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=14a96098b608e571bc3437c0ecd6a4da8f4a570c1359b7e73e9b62c45e68a03f&X-Amz-SignedHeaders=host&partNumber=7&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2393)')))\"), '(Request ID: d228e4fa-0e0d-4875-85d5-3527a42fd110)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/d3/07/d3078206a56a158a9e339b1246e868ae53f7b08346c1377b2da709e87c166515/15068f809a69068c510d55965b7451248f33f977ac12ea3a878b08303915a80d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250528%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250528T120318Z&X-Amz-Expires=86400&X-Amz-Signature=14a96098b608e571bc3437c0ecd6a4da8f4a570c1359b7e73e9b62c45e68a03f&X-Amz-SignedHeaders=host&partNumber=7&uploadId=PY32UJOIhw0F9zdboZNnBsFpztYg2A2VPgJRjw9mvpITyCLigNqlnZDLOwL0fa1N0WnkacQSpuITT24xZlsErgINQLyR5Lz4KwrsOmk6fsfh4rUmbalIC59ATJJXzRTU&x-id=UploadPart\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"carbon-intensity-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad83739-f2d5-4474-9c1f-49166e337b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'high', 'score': 0.5594532489776611}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"jessica-ecosia/carbon-intensity-classifier\")\n",
    "\n",
    "pipe(\"flying Berlin to Italy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42091a86-5150-4c1e-9804-7e409edf87e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'medium', 'score': 0.4121767580509186}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"train Berlin to Italy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
